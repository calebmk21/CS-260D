{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"wsFYbGhGODOq"},"outputs":[],"source":["!pip install opacus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FBypp9wHY7D"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","import torch.nn.utils.prune as prune\n","import numpy as np\n","from opacus import PrivacyEngine\n","import time\n","import copy"]},{"cell_type":"markdown","metadata":{"id":"J9ONY2zRH0qh"},"source":["## Model Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFp58fAnHgn_"},"outputs":[],"source":["def select_dataset(name='MNIST'):\n","  if name == \"MNIST\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,)),])\n","\n","    full_train = datasets.MNIST(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 50000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","    test_dataset = datasets.MNIST(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  elif name == \"CIFAR\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n","\n","\n","    full_train = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 40000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","\n","    test_dataset = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","  val_loader   = DataLoader(val_dataset, batch_size=256, shuffle=False)\n","  test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)\n","  return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBkme2WxGxhP"},"outputs":[],"source":["BATCH_SIZE = 128\n","LR = 0.01\n","EPOCHS = 20\n","SEED = 42\n","MAX_GRAD_NORM = 1.0\n","DELTA = 1e-5\n","PATIENCE = 5\n","\n","DATASET_NAME = \"MNIST\"\n","train_loader, val_loader, test_loader = select_dataset(DATASET_NAME)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# For dynamically calculated epsilon\n","NOISE_MULTIPLIER = 1.0\n","\n","# For a fixed privacy budget (eps, del)\n","TARGET_EPSILON = 8\n","TARGET_DELTA = 1e-5\n","NUM_EPOCHS = 20\n","\n","PRUNE_EPOCHS = 2\n","\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwolYxpqKzlX"},"outputs":[],"source":["# baseline model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        # self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        # self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        # self.fc1 = nn.Linear(32*12*12, 64)\n","        # self.fc2 = nn.Linear(64, 10)\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","        # x = F.relu(self.conv1(x))\n","        # x = F.relu(self.conv2(x))\n","        # x = F.max_pool2d(x, 2)\n","        # x = torch.flatten(x, 1)\n","        # x = F.relu(self.fc1(x))\n","        # return self.fc2(x)\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1LOVbdfJh1v"},"outputs":[],"source":["# MNIST Model\n","class CNN_MNIST(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.fc1 = nn.Linear(32*12*12, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","\n","# CIFAR-10 Model\n","\n","class CNN_CIFAR10(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOBiaI6uPBX8"},"outputs":[],"source":["def train_one_epoch(model, loader, optimizer):\n","    # train loop\n","    model.train()\n","    total_loss = 0\n","    for batch_idx, (data, target) in enumerate(loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.cross_entropy(out, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-dGAVm7PK_E"},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, loader):\n","    model.eval()\n","    loss, correct = 0, 0\n","    for data, target in loader:\n","        data, target = data.to(device), target.to(device)\n","        out = model(data)\n","        loss += F.cross_entropy(out, target, reduction=\"sum\").item()\n","        pred = out.argmax(1)\n","        correct += pred.eq(target).sum().item()\n","    loss /= len(loader.dataset)\n","    acc = 100. * correct / len(loader.dataset)\n","    return loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPcsKaOe78YW"},"outputs":[],"source":["def weight_pruning(model, amount, return_mask=False, remove=True):\n","    parameters_to_prune = [\n","        (m, \"weight\") for m in model.modules()\n","        if isinstance(m, (nn.Conv2d, nn.Linear))\n","    ]\n","\n","    prune.global_unstructured(\n","        parameters_to_prune,\n","        pruning_method=prune.L1Unstructured,\n","        amount=amount,\n","    )\n","\n","    mask_dict = None\n","    if return_mask:\n","        mask_dict = {\n","            f\"{name}.weight\": module.weight_mask.detach().clone()\n","            for name, module in model.named_modules()\n","            if hasattr(module, \"weight_mask\")\n","        }\n","\n","    if remove:\n","      for module, _ in parameters_to_prune:\n","          prune.remove(module, \"weight\")\n","\n","    total = sum(p.numel() for p in model.parameters())\n","    zeros = sum((p == 0).sum().item() for p in model.parameters())\n","    sparsity = 100 * zeros / total\n","\n","    print(f\"Pruned model sparsity = {sparsity:.2f}%\")\n","\n","    return model, mask_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Reix1kZyTtU0"},"outputs":[],"source":["def calculate_sparsity(model):\n","    total = zeros = 0\n","    for name, p in model.named_parameters():\n","        if \"weight\" in name:\n","            arr = p.detach().cpu().numpy()\n","            total += arr.size\n","            zeros += (arr == 0).sum()\n","    return 100 * zeros / total"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODNJvgYDHhIt"},"outputs":[],"source":["def run_experiment(dataset='MNIST', use_dp=False, pruning_type=None, final_sparsity=None, fixed_privacy_budget=True, prune_epochs=None):\n","\n","    # setup model and optimizer\n","    if dataset == 'MNIST':\n","      model = CNN_MNIST().to(device)\n","    elif dataset == \"CIFAR\":\n","      model = CNN_CIFAR10().to(device)\n","\n","    # Defaults to base CNN class if no dataset is specified\n","    else:\n","      model = CNN().to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n","\n","    if pruning_type == \"PRE\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, final_sparsity)\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      final_sparsity = calculate_sparsity(model)\n","\n","    privacy_engine = None\n","    if use_dp:\n","\n","        if fixed_privacy_budget:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Calculates sigma based on target epsilon and delta\n","            model, optimizer, train_loader_dp = privacy_engine.make_private_with_epsilon(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              target_delta=TARGET_DELTA,\n","              target_epsilon=TARGET_EPSILON,\n","              epochs=NUM_EPOCHS\n","        )\n","        else:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Otherwise takes sigma as a hyperparameter\n","            model, optimizer, train_loader_dp = privacy_engine.make_private(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              noise_multiplier=NOISE_MULTIPLIER,\n","        )\n","    else:\n","        train_loader_dp = train_loader\n","\n","\n","    # train\n","    sparsity = 0\n","    prune_time = 0\n","    best_val_acc = 0\n","    epochs_no_improve = 0\n","    best_model_path = f\"best_model{'_dp' if use_dp else ''}.pt\"\n","    rewind_state = None\n","    global_mask = None\n","    if pruning_type == \"LTH\":\n","      prune_steps = max(1, EPOCHS - 2)\n","      train_epochs = EPOCHS\n","      lth_step = 0\n","    elif pruning_type == \"POST\":\n","      train_epochs = EPOCHS - PRUNE_EPOCHS\n","    else:\n","      train_epochs = EPOCHS\n","\n","    start_time = time.time()\n","\n","    for epoch in range(1, train_epochs + 1):\n","        train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","        val_loss, val_acc = evaluate(model, val_loader)\n","\n","        eps = privacy_engine.get_epsilon(DELTA)  if use_dp else None\n","\n","        print(f\"[{'DP-SGD' if use_dp else 'Standard SGD'}] Epoch {epoch}: \"\n","            + f\"train_loss={train_loss:.4f}, \"\n","            + f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}%\"\n","            + f\", ε={eps:.4f}\" if use_dp else \"\")\n","\n","        if pruning_type == \"LTH\" and epoch == 1:\n","            rewind_state = copy.deepcopy(model.state_dict())\n","            print(\"Saved early-rewind weights for LTH\")\n","\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), best_model_path)\n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= PATIENCE:\n","            print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {PATIENCE} epochs).\")\n","            break\n","\n","        if pruning_type == \"LTH\" and epoch != 1 and epoch in prune_epochs:\n","          lth_step += 1\n","          remaining_k = (1 - final_sparsity) ** (lth_step / len(prune_epochs))\n","          target_sparsity = 1 - remaining_k\n","          print(f\"Pruning {target_sparsity*100:.2f}% at epoch {epoch}\")\n","          model, new_mask = weight_pruning(model, amount=target_sparsity, return_mask=True)\n","          global_mask = new_mask\n","\n","          rewound = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in rewound:\n","                  rewound[name] = rewound[name] * mask   # apply lottery ticket mask\n","\n","          model.load_state_dict(rewound)\n","          epochs_no_improve = 0\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","\n","    if pruning_type == \"POST\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, final_sparsity)\n","      final_sparsity = calculate_sparsity(model)\n","\n","      for ft_epoch in range(1, PRUNE_EPOCHS + 1):\n","            train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","            val_loss, val_acc = evaluate(model, val_loader)\n","            eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","\n","            print(f\"[Fine Tuning Epoch {ft_epoch}] val_acc={val_acc:.4f}%\"\n","                  + (f\", ε={eps:.4f}\" if use_dp else \"\"))\n","            if val_acc > best_val_acc:\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), best_model_path)\n","\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      end_time = time.time()\n","      total_time = end_time - start_time\n","\n","    # test on best model\n","    if pruning_type == \"LTH\":\n","      # reconstruct final winning ticket\n","      if global_mask is None:\n","          ticket_state = copy.deepcopy(rewind_state)\n","      else:\n","          ticket_state = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in ticket_state:\n","                  ticket_state[name] = ticket_state[name] * mask\n","      model.load_state_dict(ticket_state)\n","    elif pruning_type == \"POST\":\n","      # keep already pruned & fine-tuned model\n","      pass\n","    else:\n","      model.load_state_dict(torch.load(best_model_path))\n","    test_loss, test_acc = evaluate(model, test_loader)\n","    final_eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","    final_sparsity = calculate_sparsity(model)\n","\n","    print(f\"\\n=== Results for {'DP-SGD' if use_dp else 'Standard-SGD'} with {pruning_type if pruning_type else 'No'} Pruning ===\")\n","    print(f\"Test Accuracy: {test_acc:.2f}%\")\n","    print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n","    if use_dp:\n","        print(f\"Final ε = {final_eps:.3f}\")\n","    print(f\"Train Time:     {total_time:.2f} sec\")\n","    if pruning_type:\n","        print(f\"Sparsity:       {final_sparsity:.2f}%\")\n","\n","    return {\n","        \"val_acc\": best_val_acc,\n","        \"test_acc\": test_acc,\n","        \"epsilon\": final_eps,\n","        \"train_time\": total_time,\n","        \"sparsity\": final_sparsity\n","    }"]},{"cell_type":"markdown","metadata":{"id":"H7wfuU3iJ7M9"},"source":["# Baseline: No Differential Privacy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LT9id_MwJxpC"},"outputs":[],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDIkJaqVQZc8"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WutQvKhLs6Cc"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Und-QJTDeVB"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"markdown","metadata":{"id":"8F8KH8ZWH9ZB"},"source":["MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c05kbWWJOE3U"},"outputs":[],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xsO3AzzH_QI"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mGXspQ4eICC4"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qrcaGz2aIEaq"},"outputs":[],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWTtNpkFIHQj"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}