{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":12518,"status":"ok","timestamp":1765156785852,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"wsFYbGhGODOq","outputId":"09ee0bbf-5516-4e99-c9ff-4c4dedf4d7b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opacus\n","  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.9.0+cu126)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.3)\n","Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opacus\n","Successfully installed opacus-1.5.4\n"]}],"source":["!pip install opacus"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17660,"status":"ok","timestamp":1765156803521,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"2FBypp9wHY7D"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","import torch.nn.utils.prune as prune\n","import numpy as np\n","from opacus import PrivacyEngine\n","import time\n","import copy"]},{"cell_type":"markdown","metadata":{"id":"J9ONY2zRH0qh"},"source":["## Model Hyperparameters"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1765156803542,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"RFp58fAnHgn_"},"outputs":[],"source":["def select_dataset(name='MNIST'):\n","  if name == \"MNIST\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,)),])\n","\n","    full_train = datasets.MNIST(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 50000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","    test_dataset = datasets.MNIST(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  elif name == \"CIFAR\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n","\n","\n","    full_train = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 40000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","\n","    test_dataset = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","  val_loader   = DataLoader(val_dataset, batch_size=256, shuffle=False)\n","  test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)\n","  return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51531,"status":"ok","timestamp":1765156855078,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"bBkme2WxGxhP","outputId":"b622f6b2-30f7-4e8d-aa0d-a6ca313719e8"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:47<00:00, 3.62MB/s]\n"]}],"source":["BATCH_SIZE = 128\n","LR = 0.01\n","EPOCHS = 20\n","SEED = 42\n","MAX_GRAD_NORM = 1.0\n","DELTA = 1e-5\n","PATIENCE = 5\n","\n","DATASET_NAME = \"CIFAR\"\n","train_loader, val_loader, test_loader = select_dataset(DATASET_NAME)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# For dynamically calculated epsilon\n","NOISE_MULTIPLIER = 1.0\n","\n","# For a fixed privacy budget (eps, del)\n","TARGET_EPSILON = 8\n","TARGET_DELTA = 1e-5\n","NUM_EPOCHS = 20\n","\n","PRUNE_EPOCHS = 2\n","\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1765156855099,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"dwolYxpqKzlX"},"outputs":[],"source":["# baseline model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        # self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        # self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        # self.fc1 = nn.Linear(32*12*12, 64)\n","        # self.fc2 = nn.Linear(64, 10)\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","        # x = F.relu(self.conv1(x))\n","        # x = F.relu(self.conv2(x))\n","        # x = F.max_pool2d(x, 2)\n","        # x = torch.flatten(x, 1)\n","        # x = F.relu(self.fc1(x))\n","        # return self.fc2(x)\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1765156855111,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"G1LOVbdfJh1v"},"outputs":[],"source":["# MNIST Model\n","class CNN_MNIST(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.fc1 = nn.Linear(32*12*12, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","\n","# CIFAR-10 Model\n","\n","class CNN_CIFAR10(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1765156855121,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"QOBiaI6uPBX8"},"outputs":[],"source":["def train_one_epoch(model, loader, optimizer):\n","    # train loop\n","    model.train()\n","    total_loss = 0\n","    for batch_idx, (data, target) in enumerate(loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.cross_entropy(out, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1765156855131,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"t-dGAVm7PK_E"},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, loader):\n","    # evaluation\n","    model.eval()\n","    loss, correct = 0, 0\n","    for data, target in loader:\n","        data, target = data.to(device), target.to(device)\n","        out = model(data)\n","        loss += F.cross_entropy(out, target, reduction=\"sum\").item()\n","        pred = out.argmax(1)\n","        correct += pred.eq(target).sum().item()\n","    loss /= len(loader.dataset)\n","    acc = 100. * correct / len(loader.dataset)\n","    return loss, acc"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1765156855140,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"vPcsKaOe78YW"},"outputs":[],"source":["def weight_pruning(model, amount, return_mask=False, remove=True):\n","    parameters_to_prune = [\n","        (m, \"weight\") for m in model.modules()\n","        if isinstance(m, (nn.Conv2d, nn.Linear))\n","    ]\n","\n","    prune.global_unstructured(\n","        parameters_to_prune,\n","        pruning_method=prune.L1Unstructured,\n","        amount=amount,\n","    )\n","\n","    mask_dict = None\n","    if return_mask:\n","        mask_dict = {\n","            f\"{name}.weight\": module.weight_mask.detach().clone()\n","            for name, module in model.named_modules()\n","            if hasattr(module, \"weight_mask\")\n","        }\n","\n","    if remove:\n","      for module, _ in parameters_to_prune:\n","          prune.remove(module, \"weight\")\n","\n","    total = sum(p.numel() for p in model.parameters())\n","    zeros = sum((p == 0).sum().item() for p in model.parameters())\n","    sparsity = 100 * zeros / total\n","\n","    print(f\"Pruned model sparsity = {sparsity:.2f}%\")\n","\n","    return model, mask_dict"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1765156855152,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"VkbvTjUqDYDF"},"outputs":[],"source":["def compute_imp_prune_amount(prune_amount, num_iterations):\n","    remaining = 1 - prune_amount\n","    p = 1 - remaining ** (1 / num_iterations)\n","    return p"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1765156855166,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"Reix1kZyTtU0"},"outputs":[],"source":["def calculate_sparsity(model):\n","    total = zeros = 0\n","    for name, p in model.named_parameters():\n","        if \"weight\" in name:\n","            arr = p.detach().cpu().numpy()\n","            total += arr.size\n","            zeros += (arr == 0).sum()\n","    return 100 * zeros / total"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1765156855174,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"ODNJvgYDHhIt"},"outputs":[],"source":["def run_experiment(dataset='MNIST', use_dp=False, pruning_type=None, final_sparsity=None, fixed_privacy_budget=True, prune_epochs=None):\n","\n","    # setup model and optimizer\n","    if dataset == 'MNIST':\n","      model = CNN_MNIST().to(device)\n","    elif dataset == \"CIFAR\":\n","      model = CNN_CIFAR10().to(device)\n","\n","    # Defaults to base CNN class if no dataset is specified\n","    else:\n","      model = CNN().to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n","\n","    privacy_engine = None\n","    if use_dp:\n","\n","        if fixed_privacy_budget:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Calculates sigma based on target epsilon and delta\n","            model, optimizer, train_loader_dp = privacy_engine.make_private_with_epsilon(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              target_delta=TARGET_DELTA,\n","              target_epsilon=TARGET_EPSILON,\n","              epochs=NUM_EPOCHS\n","        )\n","        else:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Otherwise takes sigma as a hyperparameter\n","            model, optimizer, train_loader_dp = privacy_engine.make_private(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              noise_multiplier=NOISE_MULTIPLIER,\n","        )\n","    else:\n","        train_loader_dp = train_loader\n","\n","\n","    # train\n","    sparsity = 0\n","    prune_time = 0\n","    best_val_acc = 0\n","    epochs_no_improve = 0\n","    best_model_path = f\"best_model{'_dp' if use_dp else ''}.pt\"\n","    rewind_state = None\n","    global_mask = None\n","    if pruning_type == \"LTH\":\n","      prune_steps = max(1, EPOCHS - 2)\n","      train_epochs = EPOCHS\n","      lth_step = 0\n","    elif pruning_type == \"POST\":\n","      prune_amount = final_sparsity\n","      train_epochs = EPOCHS - PRUNE_EPOCHS\n","    else:\n","      prune_amount = final_sparsity\n","      train_epochs = EPOCHS\n","\n","    if pruning_type == \"PRE\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, prune_amount)\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      final_sparsity = calculate_sparsity(model)\n","\n","    start_time = time.time()\n","\n","    for epoch in range(1, train_epochs + 1):\n","        train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","        val_loss, val_acc = evaluate(model, val_loader)\n","\n","        eps = privacy_engine.get_epsilon(DELTA)  if use_dp else None\n","\n","        print(f\"[{'DP-SGD' if use_dp else 'Standard SGD'}] Epoch {epoch}: \"\n","            + f\"train_loss={train_loss:.4f}, \"\n","            + f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}%\"\n","            + f\", ε={eps:.4f}\" if use_dp else \"\")\n","\n","        if pruning_type == \"LTH\" and epoch == 1:\n","            rewind_state = copy.deepcopy(model.state_dict())\n","            print(\"Saved early-rewind weights for LTH\")\n","\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), best_model_path)\n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= PATIENCE:\n","            print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {PATIENCE} epochs).\")\n","            break\n","\n","        if pruning_type == \"LTH\" and epoch != 1 and epoch in prune_epochs:\n","          lth_step += 1\n","          remaining_k = (1 - final_sparsity) ** (lth_step / len(prune_epochs))\n","          target_sparsity = 1 - remaining_k\n","          print(f\"Pruning {target_sparsity*100:.2f}% at epoch {epoch}\")\n","          model, new_mask = weight_pruning(model, amount=target_sparsity, return_mask=True)\n","          global_mask = new_mask\n","\n","          rewound = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in rewound:\n","                  rewound[name] = rewound[name] * mask   # apply lottery ticket mask\n","\n","          model.load_state_dict(rewound)\n","          epochs_no_improve = 0\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","\n","    if pruning_type == \"POST\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, amount=prune_amount)\n","      final_sparsity = calculate_sparsity(model)\n","\n","      for ft_epoch in range(1, PRUNE_EPOCHS + 1):\n","            train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","            val_loss, val_acc = evaluate(model, val_loader)\n","            eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","\n","            print(f\"[Fine Tuning Epoch {ft_epoch}] val_acc={val_acc:.4f}%\"\n","                  + (f\", ε={eps:.4f}\" if use_dp else \"\"))\n","            if val_acc > best_val_acc:\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), best_model_path)\n","\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      end_time = time.time()\n","      total_time = end_time - start_time\n","\n","    # test on best model\n","    if pruning_type == \"LTH\":\n","      # reconstruct final winning ticket\n","      if global_mask is None:\n","          ticket_state = copy.deepcopy(rewind_state)\n","      else:\n","          ticket_state = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in ticket_state:\n","                  ticket_state[name] = ticket_state[name] * mask\n","      model.load_state_dict(ticket_state)\n","    elif pruning_type == \"POST\":\n","      # keep already pruned & fine-tuned model\n","      pass\n","    else:\n","      model.load_state_dict(torch.load(best_model_path))\n","    test_loss, test_acc = evaluate(model, test_loader)\n","    final_eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","    final_sparsity = calculate_sparsity(model)\n","\n","    print(f\"\\n=== Results for {'DP-SGD' if use_dp else 'Standard-SGD'} with {pruning_type if pruning_type else 'No'} Pruning ===\")\n","    print(f\"Test Accuracy: {test_acc:.2f}%\")\n","    print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n","    if use_dp:\n","        print(f\"Final ε = {final_eps:.3f}\")\n","    print(f\"Train Time:     {total_time:.2f} sec\")\n","    if pruning_type:\n","        print(f\"Sparsity:       {final_sparsity:.2f}%\")\n","\n","    return {\n","        \"val_acc\": best_val_acc,\n","        \"test_acc\": test_acc,\n","        \"epsilon\": final_eps,\n","        \"train_time\": total_time,\n","        \"sparsity\": final_sparsity\n","    }"]},{"cell_type":"code","source":["def magnitude_prune_mask(model, amount):\n","    all_weights = torch.cat([\n","        p.detach().abs().flatten()\n","        for n, p in model.named_parameters()\n","        if \"weight\" in n\n","    ])\n","\n","    k = int((1 - amount) * all_weights.numel())\n","    threshold = all_weights.kthvalue(k).values.item()\n","\n","    mask = {}\n","    for name, param in model.named_parameters():\n","        if \"weight\" in name:\n","            mask[name] = (param.detach().abs() > threshold).float()\n","    return mask"],"metadata":{"id":"JqvxL_W49-67","executionInfo":{"status":"ok","timestamp":1765156855184,"user_tz":300,"elapsed":6,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def weight_pruning(model, amount, return_mask=False, remove=True):\n","    parameters_to_prune = [\n","        (m, \"weight\") for m in model.modules()\n","        if isinstance(m, (nn.Conv2d, nn.Linear))\n","    ]\n","\n","    prune.global_unstructured(\n","        parameters_to_prune,\n","        pruning_method=prune.L1Unstructured,\n","        amount=amount,\n","    )\n","\n","    mask_dict = None\n","    if return_mask:\n","        mask_dict = {\n","            f\"{name}.weight\": module.weight_mask.detach().clone()\n","            for name, module in model.named_modules()\n","            if hasattr(module, \"weight_mask\")\n","        }\n","\n","    if remove:\n","      for module, _ in parameters_to_prune:\n","          prune.remove(module, \"weight\")\n","\n","    total = sum(p.numel() for p in model.parameters())\n","    zeros = sum((p == 0).sum().item() for p in model.parameters())\n","    sparsity = 100 * zeros / total\n","\n","    print(f\"Pruned model sparsity = {sparsity:.2f}%\")\n","\n","    return model, mask_dict"],"metadata":{"id":"lkVA2ZyisuTF","executionInfo":{"status":"ok","timestamp":1765156855196,"user_tz":300,"elapsed":15,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def magnitude_pruning(model, amount):\n","    all_weights = torch.cat([\n","        p.detach().abs().flatten()\n","        for n, p in model.named_parameters()\n","        if \"weight\" in n\n","    ])\n","\n","    k = int(amount * all_weights.numel())\n","    if k == 0:\n","        return {}\n","\n","    threshold = torch.topk(all_weights, k, largest=False).values.max()\n","    mask = {}\n","    for name, p in model.named_parameters():\n","        if \"weight\" in name:\n","            mask[name] = (p.data.abs() > threshold).float()\n","    return mask"],"metadata":{"id":"K1GIhqmjBx-y","executionInfo":{"status":"ok","timestamp":1765156855201,"user_tz":300,"elapsed":12,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def apply_mask(model, mask):\n","    with torch.no_grad():\n","        for name, param in model.named_parameters():\n","            if name in mask:\n","                param.mul_(mask[name])"],"metadata":{"id":"NpX912SP-JWG","executionInfo":{"status":"ok","timestamp":1765156855208,"user_tz":300,"elapsed":13,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, loader, optimizer, mask=None):\n","    model.train()\n","    total_loss = 0\n","    for batch_idx, (data, target) in enumerate(loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.cross_entropy(out, target)\n","        loss.backward()\n","        optimizer.step()\n","        if mask is not None:\n","            apply_mask(model, mask)\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"],"metadata":{"id":"9V6K1FCn-MCi","executionInfo":{"status":"ok","timestamp":1765156855209,"user_tz":300,"elapsed":5,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def run_lth_dp(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True,\n","                          prune_rounds=2,\n","                          final_sparsity=0.3,\n","                          rewind_epochs=1):\n","  # setup model and optimizer\n","    if dataset == 'MNIST':\n","      model = CNN_MNIST().to(device)\n","    elif dataset == \"CIFAR\":\n","      model = CNN_CIFAR10().to(device)\n","\n","    # Defaults to base CNN class if no dataset is specified\n","    else:\n","      model = CNN().to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n","\n","    privacy_engine = None\n","    if use_dp:\n","\n","        if fixed_privacy_budget:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Calculates sigma based on target epsilon and delta\n","            model, optimizer, train_loader_dp = privacy_engine.make_private_with_epsilon(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              target_delta=TARGET_DELTA,\n","              target_epsilon=TARGET_EPSILON,\n","              epochs=NUM_EPOCHS*2\n","        )\n","        else:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Otherwise takes sigma as a hyperparameter\n","            model, optimizer, train_loader_dp = privacy_engine.make_private(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              noise_multiplier=NOISE_MULTIPLIER,\n","        )\n","    else:\n","        train_loader_dp = train_loader\n","\n","    start_time = time.time()\n","\n","    # rewind state\n","    for e in range(1, rewind_epochs + 1):\n","        train_one_epoch(model, train_loader_dp, optimizer, mask=None)\n","\n","    rewind_state = copy.deepcopy(model.state_dict())\n","\n","    current_mask = None\n","    for r in range(1, prune_rounds+1):\n","        round_start_time = time.time()\n","        for epoch in range(rewind_epochs + 1, EPOCHS + 1):\n","            train_loss = train_one_epoch(model, train_loader, optimizer, mask=current_mask)\n","            val_loss, val_acc = evaluate(model, val_loader)\n","\n","            eps = privacy_engine.get_epsilon(DELTA)  if use_dp else None\n","\n","            print(f\"[{'DP-SGD' if use_dp else 'Standard SGD'}] Epoch {epoch}, LTH Iteration {r}: \"\n","            + f\"train_loss={train_loss:.4f}, \"\n","            + f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}%\"\n","            + f\", ε={eps:.4f}\" if use_dp else \"\")\n","\n","        target_sparsity = 1 - (1 - final_sparsity)**(r/prune_rounds)\n","        print(f\"Pruning {target_sparsity*100:.2f}% at epoch {epoch}\")\n","        new_mask = magnitude_pruning(model, amount=target_sparsity)\n","\n","        if current_mask is None:\n","            current_mask = new_mask\n","        else:\n","            for name in current_mask:\n","                current_mask[name] = current_mask[name] * new_mask[name]\n","\n","        model.load_state_dict(rewind_state)\n","        apply_mask(model, current_mask)\n","        round_time = time.time() - round_start_time\n","        print(f\"LTH Iteration {r} Time:     {round_time:.2f} sec\")\n","\n","        # lth_step += 1\n","        # remaining_k = (1 - prune_amount) ** (lth_step / len(prune_epochs))\n","        # target_sparsity = 1 - remaining_k\n","        # new_mask = magnitude_prune_mask(model, target_sparsity)\n","\n","        # # combine with previous masks\n","        # if current_mask is None:\n","        #     current_mask = new_mask\n","        # else:\n","        #     for name in current_mask:\n","        #         current_mask[name] = current_mask[name] * new_mask[name]\n","\n","        # # rewind\n","        # model.load_state_dict(rewind_state)\n","\n","        # apply_mask(model, current_mask)\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","\n","    test_loss, test_acc = evaluate(model, test_loader)\n","    final_eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","    final_sparsity = calculate_sparsity(model)\n","\n","    print(f\"\\n=== Results for {'DP-SGD' if use_dp else 'Standard-SGD'} with LTH Pruning ===\")\n","    print(f\"Test Accuracy: {test_acc:.2f}%\")\n","    print(f\"Final ε = {final_eps:.3f}\")\n","    print(f\"Train Time:     {total_time:.2f} sec\")\n","    print(f\"Sparsity:       {final_sparsity:.2f}%\")\n","\n","    return {\n","        \"test_acc\": test_acc,\n","        \"epsilon\": final_eps,\n","        \"train_time\": total_time,\n","        \"sparsity\": final_sparsity\n","    }"],"metadata":{"id":"DbN2xTlK-QdG","executionInfo":{"status":"ok","timestamp":1765156855214,"user_tz":300,"elapsed":4,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["run_lth_dp(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True,\n","                          prune_rounds=2,\n","                          final_sparsity=0.3,\n","                          rewind_epochs=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOla4yJKp3_q","executionInfo":{"status":"ok","timestamp":1765158155873,"user_tz":300,"elapsed":1300661,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}},"outputId":"b034e89f-42cb-41b4-b5b8-4b125c1f362c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/tmp/ipython-input-3673616273.py:9: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 2, LTH Iteration 1: train_loss=1.9922, val_loss=1.9628, val_acc=30.9300%, ε=3.0262\n","[DP-SGD] Epoch 3, LTH Iteration 1: train_loss=1.9436, val_loss=1.9402, val_acc=32.1500%, ε=3.3019\n","[DP-SGD] Epoch 4, LTH Iteration 1: train_loss=1.9224, val_loss=1.9196, val_acc=33.4400%, ε=3.5338\n","[DP-SGD] Epoch 5, LTH Iteration 1: train_loss=1.8961, val_loss=1.8944, val_acc=34.6400%, ε=3.7406\n","[DP-SGD] Epoch 6, LTH Iteration 1: train_loss=1.8696, val_loss=1.8680, val_acc=35.5400%, ε=3.9306\n","[DP-SGD] Epoch 7, LTH Iteration 1: train_loss=1.8442, val_loss=1.8436, val_acc=36.7200%, ε=4.1084\n","[DP-SGD] Epoch 8, LTH Iteration 1: train_loss=1.8152, val_loss=1.8113, val_acc=37.9900%, ε=4.2767\n","[DP-SGD] Epoch 9, LTH Iteration 1: train_loss=1.7946, val_loss=1.8062, val_acc=38.0900%, ε=4.4373\n","[DP-SGD] Epoch 10, LTH Iteration 1: train_loss=1.7876, val_loss=1.7927, val_acc=38.8900%, ε=4.5915\n","[DP-SGD] Epoch 11, LTH Iteration 1: train_loss=1.7759, val_loss=1.7951, val_acc=39.4100%, ε=4.7402\n","[DP-SGD] Epoch 12, LTH Iteration 1: train_loss=1.7694, val_loss=1.7964, val_acc=39.9000%, ε=4.8841\n","[DP-SGD] Epoch 13, LTH Iteration 1: train_loss=1.7723, val_loss=1.8010, val_acc=40.7700%, ε=5.0238\n","[DP-SGD] Epoch 14, LTH Iteration 1: train_loss=1.7835, val_loss=1.8026, val_acc=41.1500%, ε=5.1598\n","[DP-SGD] Epoch 15, LTH Iteration 1: train_loss=1.7783, val_loss=1.8069, val_acc=41.6600%, ε=5.2924\n","[DP-SGD] Epoch 16, LTH Iteration 1: train_loss=1.7840, val_loss=1.7889, val_acc=41.8700%, ε=5.4220\n","[DP-SGD] Epoch 17, LTH Iteration 1: train_loss=1.7813, val_loss=1.8147, val_acc=42.2800%, ε=5.5487\n","[DP-SGD] Epoch 18, LTH Iteration 1: train_loss=1.7922, val_loss=1.8238, val_acc=42.9300%, ε=5.6730\n","[DP-SGD] Epoch 19, LTH Iteration 1: train_loss=1.7929, val_loss=1.8182, val_acc=43.3400%, ε=5.7948\n","[DP-SGD] Epoch 20, LTH Iteration 1: train_loss=1.7956, val_loss=1.8345, val_acc=43.4600%, ε=5.9145\n","Pruning 16.33% at epoch 20\n","LTH Iteration 1 Time:     616.08 sec\n","[DP-SGD] Epoch 2, LTH Iteration 2: train_loss=1.9869, val_loss=1.9584, val_acc=30.6500%, ε=6.0321\n","[DP-SGD] Epoch 3, LTH Iteration 2: train_loss=1.9379, val_loss=1.9325, val_acc=32.8000%, ε=6.1478\n","[DP-SGD] Epoch 4, LTH Iteration 2: train_loss=1.9092, val_loss=1.9079, val_acc=34.0700%, ε=6.2617\n","[DP-SGD] Epoch 5, LTH Iteration 2: train_loss=1.8818, val_loss=1.8752, val_acc=35.1000%, ε=6.3739\n","[DP-SGD] Epoch 6, LTH Iteration 2: train_loss=1.8483, val_loss=1.8521, val_acc=36.2100%, ε=6.4845\n","[DP-SGD] Epoch 7, LTH Iteration 2: train_loss=1.8255, val_loss=1.8409, val_acc=36.9100%, ε=6.5936\n","[DP-SGD] Epoch 8, LTH Iteration 2: train_loss=1.8045, val_loss=1.8061, val_acc=38.1900%, ε=6.7013\n","[DP-SGD] Epoch 9, LTH Iteration 2: train_loss=1.7857, val_loss=1.7879, val_acc=38.8800%, ε=6.8077\n","[DP-SGD] Epoch 10, LTH Iteration 2: train_loss=1.7718, val_loss=1.7864, val_acc=39.5200%, ε=6.9127\n","[DP-SGD] Epoch 11, LTH Iteration 2: train_loss=1.7625, val_loss=1.8000, val_acc=40.2900%, ε=7.0166\n","[DP-SGD] Epoch 12, LTH Iteration 2: train_loss=1.7556, val_loss=1.7853, val_acc=40.9600%, ε=7.1192\n","[DP-SGD] Epoch 13, LTH Iteration 2: train_loss=1.7558, val_loss=1.7743, val_acc=41.4500%, ε=7.2208\n","[DP-SGD] Epoch 14, LTH Iteration 2: train_loss=1.7549, val_loss=1.7897, val_acc=41.8000%, ε=7.3212\n","[DP-SGD] Epoch 15, LTH Iteration 2: train_loss=1.7609, val_loss=1.7969, val_acc=41.7500%, ε=7.4207\n","[DP-SGD] Epoch 16, LTH Iteration 2: train_loss=1.7619, val_loss=1.7930, val_acc=42.2100%, ε=7.5192\n","[DP-SGD] Epoch 17, LTH Iteration 2: train_loss=1.7664, val_loss=1.8027, val_acc=42.5600%, ε=7.6167\n","[DP-SGD] Epoch 18, LTH Iteration 2: train_loss=1.7685, val_loss=1.7924, val_acc=43.1700%, ε=7.7133\n","[DP-SGD] Epoch 19, LTH Iteration 2: train_loss=1.7702, val_loss=1.8057, val_acc=43.3700%, ε=7.8090\n","[DP-SGD] Epoch 20, LTH Iteration 2: train_loss=1.7842, val_loss=1.8273, val_acc=43.5800%, ε=7.9039\n","Pruning 30.00% at epoch 20\n","LTH Iteration 2 Time:     625.50 sec\n","\n","=== Results for DP-SGD with LTH Pruning ===\n","Test Accuracy: 28.90%\n","Final ε = 7.904\n","Train Time:     1270.70 sec\n","Sparsity:       30.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'test_acc': 28.9,\n"," 'epsilon': np.float64(7.9038610561231915),\n"," 'train_time': 1270.6962699890137,\n"," 'sparsity': np.float64(29.99845647252521)}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"H7wfuU3iJ7M9"},"source":["# Baseline: No Differential Privacy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":716988,"status":"ok","timestamp":1764006371210,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"LT9id_MwJxpC","outputId":"57d40e3d-40ab-410f-afa0-119a5f2cc7f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline for fixed (8, 1e-05)-DP\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=2.1917, val_loss=2.0178, val_acc=27.9000%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=1.9918, val_loss=1.9499, val_acc=31.1700%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9518, val_loss=1.9226, val_acc=32.5700%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9134, val_loss=1.9086, val_acc=33.7700%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8940, val_loss=1.8763, val_acc=35.5500%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.8705, val_loss=1.8478, val_acc=36.2500%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.8364, val_loss=1.8299, val_acc=37.0400%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8077, val_loss=1.8021, val_acc=37.7500%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.7870, val_loss=1.7713, val_acc=39.2000%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.7724, val_loss=1.7782, val_acc=40.0200%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.7721, val_loss=1.7699, val_acc=40.4600%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.7580, val_loss=1.7739, val_acc=41.4000%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.7677, val_loss=1.7540, val_acc=42.0900%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7539, val_loss=1.7776, val_acc=42.0000%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7708, val_loss=1.7859, val_acc=42.5400%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7632, val_loss=1.7986, val_acc=43.2700%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7838, val_loss=1.8029, val_acc=43.4700%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7927, val_loss=1.7968, val_acc=43.5300%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.7748, val_loss=1.8061, val_acc=43.7700%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.7879, val_loss=1.8235, val_acc=44.1600%, ε=7.9939\n","\n","=== Results for DP-SGD with No Pruning ===\n","Test Accuracy: 44.51%\n","Best Val Acc: 44.16%\n","Final ε = 7.994\n","Train Time:     695.91 sec\n"]},{"data":{"text/plain":["{'val_acc': 44.16,\n"," 'test_acc': 44.51,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 695.9134566783905,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":705715,"status":"ok","timestamp":1764093705777,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"pDIkJaqVQZc8","outputId":"f5e74f71-743f-445b-aa95-d1e7105b5da3"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with pre weight pruning\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Pruned model sparsity = 29.93%\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=2.1795, val_loss=2.0286, val_acc=27.7600%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=1.9854, val_loss=1.9519, val_acc=30.7200%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9393, val_loss=1.9201, val_acc=32.3500%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9164, val_loss=1.9014, val_acc=33.6200%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8889, val_loss=1.8650, val_acc=34.7300%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.8601, val_loss=1.8599, val_acc=35.5500%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.8517, val_loss=1.8193, val_acc=36.8200%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8174, val_loss=1.8005, val_acc=37.7900%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.7880, val_loss=1.7819, val_acc=38.4100%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.7869, val_loss=1.7846, val_acc=39.2800%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.7732, val_loss=1.7805, val_acc=39.8200%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.7628, val_loss=1.7696, val_acc=40.3800%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.7638, val_loss=1.7833, val_acc=40.9000%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7695, val_loss=1.7875, val_acc=41.3700%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7758, val_loss=1.7820, val_acc=41.9300%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7717, val_loss=1.7869, val_acc=41.9000%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7716, val_loss=1.8093, val_acc=42.4600%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7736, val_loss=1.7889, val_acc=42.5700%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.7814, val_loss=1.8089, val_acc=42.7300%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.7925, val_loss=1.8325, val_acc=43.2300%, ε=7.9939\n","\n","=== Results for DP-SGD with PRE Pruning ===\n","Test Accuracy: 43.67%\n","Best Val Acc: 43.23%\n","Final ε = 7.994\n","Train Time:     683.01 sec\n","Sparsity:       0.00%\n"]},{"data":{"text/plain":["{'val_acc': 43.23,\n"," 'test_acc': 43.67,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 683.007700920105,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":728842,"status":"ok","timestamp":1764094434605,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"WutQvKhLs6Cc","outputId":"a3e3a786-25f4-4b47-cc79-af844db5328c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with post weight pruning\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=2.2346, val_loss=2.1269, val_acc=22.8900%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=2.0741, val_loss=2.0417, val_acc=25.7500%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9967, val_loss=1.9780, val_acc=28.5200%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9407, val_loss=1.9127, val_acc=30.6300%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8807, val_loss=1.8505, val_acc=33.6300%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.8369, val_loss=1.8148, val_acc=35.7500%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.7946, val_loss=1.7972, val_acc=37.1700%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.7850, val_loss=1.7710, val_acc=37.9400%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.7740, val_loss=1.7882, val_acc=38.6500%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.7792, val_loss=1.7800, val_acc=39.4200%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.7768, val_loss=1.7796, val_acc=40.0300%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.7847, val_loss=1.8050, val_acc=40.7100%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.7904, val_loss=1.7928, val_acc=41.3900%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7940, val_loss=1.7925, val_acc=41.5500%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7797, val_loss=1.7992, val_acc=41.6200%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7763, val_loss=1.8010, val_acc=42.5200%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7813, val_loss=1.8078, val_acc=42.7000%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7722, val_loss=1.7930, val_acc=43.2600%, ε=7.6640\n","Pruned model sparsity = 29.93%\n","[Fine Tuning Epoch 1] val_acc=43.8400%, ε=7.8305\n","[Fine Tuning Epoch 2] val_acc=43.7400%, ε=7.9939\n","\n","=== Results for DP-SGD with POST Pruning ===\n","Test Accuracy: 44.67%\n","Best Val Acc: 43.84%\n","Final ε = 7.994\n","Train Time:     702.94 sec\n","Sparsity:       0.00%\n"]},{"data":{"text/plain":["{'val_acc': 43.84,\n"," 'test_acc': 44.67,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 702.9420344829559,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":758924,"status":"ok","timestamp":1764356039785,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"_Und-QJTDeVB","outputId":"8d92df36-1c84-4049-9f8c-360109ad61d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline with iterative pruning\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=2.1879, val_loss=2.0261, val_acc=26.8400%, ε=3.5278\n","Saved early-rewind weights for LTH\n","[DP-SGD] Epoch 2: train_loss=1.9955, val_loss=1.9609, val_acc=31.3300%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9416, val_loss=1.9357, val_acc=32.5400%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9191, val_loss=1.9143, val_acc=34.3100%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.9001, val_loss=1.8848, val_acc=35.6100%, ε=5.0010\n","Pruning 11.21% at epoch 5\n","Pruned model sparsity = 11.18%\n","[DP-SGD] Epoch 6: train_loss=1.9807, val_loss=1.9644, val_acc=30.9500%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.9374, val_loss=1.9255, val_acc=32.5900%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.9121, val_loss=1.9091, val_acc=34.3200%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.9035, val_loss=1.8781, val_acc=35.5100%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.8618, val_loss=1.8699, val_acc=36.4800%, ε=6.1795\n","Pruning 21.16% at epoch 10\n","Pruned model sparsity = 21.11%\n","[DP-SGD] Epoch 11: train_loss=1.9790, val_loss=1.9376, val_acc=31.7200%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.9261, val_loss=1.9150, val_acc=33.2000%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.9092, val_loss=1.8938, val_acc=34.7000%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.8820, val_loss=1.8841, val_acc=35.6700%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.8593, val_loss=1.8483, val_acc=37.1200%, ε=7.1431\n","Pruning 30.00% at epoch 15\n","Pruned model sparsity = 29.93%\n","[DP-SGD] Epoch 16: train_loss=1.9721, val_loss=1.9361, val_acc=32.0000%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.9256, val_loss=1.9165, val_acc=33.2000%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.9081, val_loss=1.8928, val_acc=34.6000%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.8778, val_loss=1.8641, val_acc=35.9600%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.8501, val_loss=1.8454, val_acc=37.1100%, ε=7.9939\n","\n","Early stopping at epoch 20 (no improvement for 5 epochs).\n","\n","=== Results for DP-SGD with LTH Pruning ===\n","Test Accuracy: 28.20%\n","Best Val Acc: 37.12%\n","Final ε = 7.994\n","Train Time:     737.01 sec\n","Sparsity:       30.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 37.12,\n"," 'test_acc': 28.2,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 737.007874250412,\n"," 'sparsity': np.float64(30.001029018316526)}"]},"metadata":{},"execution_count":26}],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"markdown","metadata":{"id":"8F8KH8ZWH9ZB"},"source":["MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3338215,"status":"ok","timestamp":1764025108823,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"c05kbWWJOE3U","outputId":"860c1dc1-c2b2-4235-e2bb-f02c07f39f22"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline for fixed (8, 1e-05)-DP\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=0.9209, val_loss=0.5501, val_acc=86.9200%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5346, val_loss=0.5889, val_acc=88.6300%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5745, val_loss=0.6062, val_acc=89.2900%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5750, val_loss=0.6006, val_acc=89.9100%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5598, val_loss=0.5834, val_acc=90.3900%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5558, val_loss=0.5712, val_acc=90.9200%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5358, val_loss=0.5597, val_acc=91.3200%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5151, val_loss=0.5546, val_acc=91.4100%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.4976, val_loss=0.5380, val_acc=91.7400%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.4853, val_loss=0.5150, val_acc=92.0300%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.4758, val_loss=0.5104, val_acc=92.2300%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.4767, val_loss=0.5070, val_acc=92.2700%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.4495, val_loss=0.5010, val_acc=92.4000%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.4420, val_loss=0.5061, val_acc=92.5700%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.4555, val_loss=0.5006, val_acc=92.8700%, ε=7.1710\n","[DP-SGD] Epoch 16: train_loss=0.4413, val_loss=0.4885, val_acc=92.9300%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.4257, val_loss=0.4859, val_acc=92.8600%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.4321, val_loss=0.4877, val_acc=93.2000%, ε=7.6817\n","[DP-SGD] Epoch 19: train_loss=0.4293, val_loss=0.4939, val_acc=93.0700%, ε=7.8449\n","[DP-SGD] Epoch 20: train_loss=0.4401, val_loss=0.4769, val_acc=93.1200%, ε=8.0050\n","\n","=== Results for DP-SGD with No Pruning ===\n","Test Accuracy: 93.93%\n","Best Val Acc: 93.20%\n","Final ε = 8.005\n","Train Time:     3316.64 sec\n"]},{"data":{"text/plain":["{'val_acc': 93.2,\n"," 'test_acc': 93.93,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3316.64049744606,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3600115,"status":"ok","timestamp":1764122042213,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"-xsO3AzzH_QI","outputId":"c2cbab2b-62a5-41ae-985a-c83ce6a9b4b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with pre weight pruning\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Pruned model sparsity = 29.99%\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=0.9401, val_loss=0.5567, val_acc=86.1700%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5412, val_loss=0.5808, val_acc=88.4700%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5531, val_loss=0.6084, val_acc=89.4200%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5635, val_loss=0.6008, val_acc=89.7800%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5529, val_loss=0.6010, val_acc=90.0500%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5376, val_loss=0.5709, val_acc=90.9400%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5266, val_loss=0.5726, val_acc=91.1400%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5048, val_loss=0.5478, val_acc=91.6200%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.4881, val_loss=0.5390, val_acc=91.7300%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.4815, val_loss=0.5053, val_acc=92.1100%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.4630, val_loss=0.5147, val_acc=92.2500%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.4597, val_loss=0.4935, val_acc=92.3900%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.4636, val_loss=0.4839, val_acc=92.6600%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.4407, val_loss=0.4801, val_acc=92.9300%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.4144, val_loss=0.4738, val_acc=93.0600%, ε=7.1710\n","[DP-SGD] Epoch 16: train_loss=0.4250, val_loss=0.4659, val_acc=93.1300%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.4333, val_loss=0.4648, val_acc=92.8900%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.4345, val_loss=0.4657, val_acc=93.1900%, ε=7.6817\n","[DP-SGD] Epoch 19: train_loss=0.4254, val_loss=0.4778, val_acc=93.2800%, ε=7.8449\n","[DP-SGD] Epoch 20: train_loss=0.4287, val_loss=0.4497, val_acc=93.3100%, ε=8.0050\n","\n","=== Results for DP-SGD with PRE Pruning ===\n","Test Accuracy: 94.30%\n","Best Val Acc: 93.31%\n","Final ε = 8.005\n","Train Time:     3576.11 sec\n","Sparsity:       0.00%\n"]},{"data":{"text/plain":["{'val_acc': 93.31,\n"," 'test_acc': 94.3,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3576.1148726940155,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mGXspQ4eICC4","outputId":"d0d7472a-0e32-4ca5-b400-6b9d29460451"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with post weight pruning\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=1.0443, val_loss=0.5630, val_acc=85.5300%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5523, val_loss=0.5927, val_acc=88.1800%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5609, val_loss=0.6007, val_acc=89.0500%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5457, val_loss=0.5906, val_acc=90.0500%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5422, val_loss=0.5860, val_acc=90.3200%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5290, val_loss=0.5756, val_acc=90.6900%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5200, val_loss=0.5783, val_acc=91.0400%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5384, val_loss=0.5642, val_acc=91.2900%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.5031, val_loss=0.5587, val_acc=91.5300%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.5077, val_loss=0.5549, val_acc=91.8100%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.5029, val_loss=0.5376, val_acc=92.0700%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.4966, val_loss=0.5402, val_acc=92.0600%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.5055, val_loss=0.5153, val_acc=92.2900%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.4701, val_loss=0.5019, val_acc=92.5400%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.4756, val_loss=0.5133, val_acc=92.6300%, ε=7.1710\n","[DP-SGD] Epoch 16: train_loss=0.4786, val_loss=0.5110, val_acc=92.7400%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.4566, val_loss=0.5022, val_acc=92.9800%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.4580, val_loss=0.4946, val_acc=92.9300%, ε=7.6817\n","Pruned model sparsity = 29.99%\n","[Fine Tuning Epoch 1] val_acc=93.1700%, ε=7.8449\n","[Fine Tuning Epoch 2] val_acc=93.2900%, ε=8.0050\n","\n","=== Results for DP-SGD with POST Pruning ===\n","Test Accuracy: 93.95%\n","Best Val Acc: 93.29%\n","Final ε = 8.005\n","Train Time:     3511.05 sec\n","Sparsity:       0.00%\n"]},{"data":{"text/plain":["{'val_acc': 93.29,\n"," 'test_acc': 93.95,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3511.04918217659,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qrcaGz2aIEaq","outputId":"af1b2e24-46dd-40e3-9c19-70f915b84bfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with iterative pruning\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n","  warnings.warn(\n","/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=0.9387, val_loss=0.5509, val_acc=86.3600%, ε=3.6072\n","Saved early-rewind weights for LTH\n","[DP-SGD] Epoch 2: train_loss=0.5379, val_loss=0.5909, val_acc=88.4700%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5762, val_loss=0.6129, val_acc=89.1800%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5621, val_loss=0.6106, val_acc=89.7400%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5560, val_loss=0.5950, val_acc=90.2900%, ε=5.0671\n","Pruning 11.21% at epoch 5\n","Pruned model sparsity = 11.21%\n","[DP-SGD] Epoch 6: train_loss=0.5238, val_loss=0.5738, val_acc=88.6700%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5516, val_loss=0.5983, val_acc=89.4700%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5553, val_loss=0.5944, val_acc=89.7500%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.5532, val_loss=0.5802, val_acc=90.4900%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.5398, val_loss=0.5563, val_acc=90.7900%, ε=6.2255\n","Pruning 21.16% at epoch 10\n","Pruned model sparsity = 21.15%\n","[DP-SGD] Epoch 11: train_loss=0.5077, val_loss=0.5743, val_acc=88.7200%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.5279, val_loss=0.5942, val_acc=89.4700%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.5437, val_loss=0.5986, val_acc=90.2000%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.5591, val_loss=0.5939, val_acc=90.4300%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.5359, val_loss=0.5613, val_acc=91.0000%, ε=7.1710\n","Pruning 30.00% at epoch 15\n","Pruned model sparsity = 29.99%\n","[DP-SGD] Epoch 16: train_loss=0.5125, val_loss=0.5519, val_acc=88.6000%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.5269, val_loss=0.5810, val_acc=89.3900%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.5342, val_loss=0.5915, val_acc=90.1800%, ε=7.6817\n","[DP-SGD] Epoch 19: train_loss=0.5336, val_loss=0.5823, val_acc=90.7300%, ε=7.8449\n","[DP-SGD] Epoch 20: train_loss=0.5302, val_loss=0.5581, val_acc=91.2100%, ε=8.0050\n","\n","=== Results for DP-SGD with LTH Pruning ===\n","Test Accuracy: 86.81%\n","Best Val Acc: 91.21%\n","Final ε = 8.005\n","Train Time:     3603.44 sec\n","Sparsity:       30.00%\n"]},{"data":{"text/plain":["{'val_acc': 91.21,\n"," 'test_acc': 86.81,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3603.4356832504272,\n"," 'sparsity': np.float64(29.999933400820503)}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWTtNpkFIHQj"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}