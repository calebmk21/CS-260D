{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":17114,"status":"ok","timestamp":1765035384377,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"wsFYbGhGODOq","outputId":"98ed4aa3-edf5-45c6-b951-ec32a4fa1add"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting opacus\n","  Downloading opacus-1.5.4-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.9.0+cu126)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.3)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.3)\n","Downloading opacus-1.5.4-py3-none-any.whl (254 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opacus\n","Successfully installed opacus-1.5.4\n"]}],"source":["!pip install opacus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FBypp9wHY7D"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","import torch.nn.utils.prune as prune\n","import numpy as np\n","from opacus import PrivacyEngine\n","import time\n","import copy"]},{"cell_type":"markdown","metadata":{"id":"J9ONY2zRH0qh"},"source":["## Model Hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFp58fAnHgn_"},"outputs":[],"source":["def select_dataset(name='MNIST'):\n","  if name == \"MNIST\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,)),])\n","\n","    full_train = datasets.MNIST(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 50000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","    test_dataset = datasets.MNIST(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  elif name == \"CIFAR\":\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n","\n","\n","    full_train = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=True,\n","        download=True,\n","        transform=transform\n","    )\n","\n","    train_size = 40000\n","    val_size = len(full_train) - train_size\n","    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])\n","\n","\n","    test_dataset = datasets.CIFAR10(\n","        root=\"./data\",\n","        train=False,\n","        download=True,\n","        transform=transform\n","    )\n","\n","  train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","  val_loader   = DataLoader(val_dataset, batch_size=256, shuffle=False)\n","  test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)\n","  return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1765047239235,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"bBkme2WxGxhP"},"outputs":[],"source":["BATCH_SIZE = 128\n","LR = 0.01\n","EPOCHS = 20\n","SEED = 42\n","MAX_GRAD_NORM = 1.0\n","DELTA = 1e-5\n","PATIENCE = 5\n","\n","DATASET_NAME = \"MNIST\"\n","train_loader, val_loader, test_loader = select_dataset(DATASET_NAME)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# For dynamically calculated epsilon\n","NOISE_MULTIPLIER = 1.0\n","\n","# For a fixed privacy budget (eps, del)\n","TARGET_EPSILON = 8\n","TARGET_DELTA = 1e-5\n","NUM_EPOCHS = 20\n","\n","PRUNE_EPOCHS = 2\n","\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwolYxpqKzlX"},"outputs":[],"source":["# baseline model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        # self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        # self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        # self.fc1 = nn.Linear(32*12*12, 64)\n","        # self.fc2 = nn.Linear(64, 10)\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","        # x = F.relu(self.conv1(x))\n","        # x = F.relu(self.conv2(x))\n","        # x = F.max_pool2d(x, 2)\n","        # x = torch.flatten(x, 1)\n","        # x = F.relu(self.fc1(x))\n","        # return self.fc2(x)\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1LOVbdfJh1v"},"outputs":[],"source":["# MNIST Model\n","class CNN_MNIST(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            MNIST Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n","        self.fc1 = nn.Linear(32*12*12, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","\n","# CIFAR-10 Model\n","\n","class CNN_CIFAR10(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        #=======================================#\n","        #            CIFAR-10 Settings\n","        #=======================================#\n","\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc1 = nn.Linear(in_features=576, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","\n","    def forward(self, x):\n","\n","        x = self.pool(torch.relu(self.conv1(x)))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1)\n","\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOBiaI6uPBX8"},"outputs":[],"source":["def train_one_epoch(model, loader, optimizer):\n","    # train loop\n","    model.train()\n","    total_loss = 0\n","    for batch_idx, (data, target) in enumerate(loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        loss = F.cross_entropy(out, target)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-dGAVm7PK_E"},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, loader):\n","    # evaluation\n","    model.eval()\n","    loss, correct = 0, 0\n","    for data, target in loader:\n","        data, target = data.to(device), target.to(device)\n","        out = model(data)\n","        loss += F.cross_entropy(out, target, reduction=\"sum\").item()\n","        pred = out.argmax(1)\n","        correct += pred.eq(target).sum().item()\n","    loss /= len(loader.dataset)\n","    acc = 100. * correct / len(loader.dataset)\n","    return loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPcsKaOe78YW"},"outputs":[],"source":["def weight_pruning(model, amount, return_mask=False, remove=True):\n","    parameters_to_prune = [\n","        (m, \"weight\") for m in model.modules()\n","        if isinstance(m, (nn.Conv2d, nn.Linear))\n","    ]\n","\n","    prune.global_unstructured(\n","        parameters_to_prune,\n","        pruning_method=prune.L1Unstructured,\n","        amount=amount,\n","    )\n","\n","    mask_dict = None\n","    if return_mask:\n","        mask_dict = {\n","            f\"{name}.weight\": module.weight_mask.detach().clone()\n","            for name, module in model.named_modules()\n","            if hasattr(module, \"weight_mask\")\n","        }\n","\n","    if remove:\n","      for module, _ in parameters_to_prune:\n","          prune.remove(module, \"weight\")\n","\n","    total = sum(p.numel() for p in model.parameters())\n","    zeros = sum((p == 0).sum().item() for p in model.parameters())\n","    sparsity = 100 * zeros / total\n","\n","    print(f\"Pruned model sparsity = {sparsity:.2f}%\")\n","\n","    return model, mask_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWdKHvcFtMXU"},"outputs":[],"source":["def structured_pruning(model, amount):\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            prune.ln_structured(\n","                module,\n","                name=\"weight\",\n","                amount=amount,\n","                n=2,\n","                dim=0\n","            )\n","\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            prune.remove(module, \"weight\")\n","\n","    total_channels = 0\n","    removed_channels = 0\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            total_channels += module.weight.shape[0]\n","            removed_channels += (module.weight.abs().sum(dim=(1,2,3)) == 0).sum().item()\n","\n","    sparsity = 100 * removed_channels / total_channels\n","    print(f\"Structured sparsity: {sparsity:.2f}%\")\n","\n","    return model, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VkbvTjUqDYDF"},"outputs":[],"source":["def compute_imp_prune_amount(prune_amount, num_iterations):\n","    remaining = 1 - prune_amount\n","    p = 1 - remaining ** (1 / num_iterations)\n","    return p"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Reix1kZyTtU0"},"outputs":[],"source":["def calculate_sparsity(model):\n","    total = zeros = 0\n","    for name, p in model.named_parameters():\n","        if \"weight\" in name:\n","            arr = p.detach().cpu().numpy()\n","            total += arr.size\n","            zeros += (arr == 0).sum()\n","    return 100 * zeros / total"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1765041805432,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"ODNJvgYDHhIt"},"outputs":[],"source":["def run_experiment(dataset='MNIST', use_dp=False, pruning_type=None, final_sparsity=None, fixed_privacy_budget=True, prune_epochs=None):\n","\n","    # setup model and optimizer\n","    if dataset == 'MNIST':\n","      model = CNN_MNIST().to(device)\n","    elif dataset == \"CIFAR\":\n","      model = CNN_CIFAR10().to(device)\n","\n","    # Defaults to base CNN class if no dataset is specified\n","    else:\n","      model = CNN().to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n","\n","    if pruning_type == \"PRE\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, final_sparsity)\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      final_sparsity = calculate_sparsity(model)\n","\n","    privacy_engine = None\n","    if use_dp:\n","\n","        if fixed_privacy_budget:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Calculates sigma based on target epsilon and delta\n","            model, optimizer, train_loader_dp = privacy_engine.make_private_with_epsilon(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              target_delta=TARGET_DELTA,\n","              target_epsilon=TARGET_EPSILON,\n","              epochs=NUM_EPOCHS\n","        )\n","        else:\n","\n","            privacy_engine = PrivacyEngine()\n","\n","            # Otherwise takes sigma as a hyperparameter\n","            model, optimizer, train_loader_dp = privacy_engine.make_private(\n","              module=model,\n","              optimizer=optimizer,\n","              data_loader=train_loader,\n","              max_grad_norm=MAX_GRAD_NORM,\n","              noise_multiplier=NOISE_MULTIPLIER,\n","        )\n","    else:\n","        train_loader_dp = train_loader\n","\n","\n","    # train\n","    sparsity = 0\n","    prune_time = 0\n","    best_val_acc = 0\n","    epochs_no_improve = 0\n","    best_model_path = f\"best_model{'_dp' if use_dp else ''}.pt\"\n","    rewind_state = None\n","    global_mask = None\n","    if pruning_type == \"LTH\":\n","      prune_steps = max(1, EPOCHS - 2)\n","      train_epochs = EPOCHS\n","      lth_step = 0\n","    elif pruning_type == \"POST\":\n","      train_epochs = EPOCHS - PRUNE_EPOCHS\n","    else:\n","      train_epochs = EPOCHS\n","\n","    start_time = time.time()\n","\n","    for epoch in range(1, train_epochs + 1):\n","        train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","        val_loss, val_acc = evaluate(model, val_loader)\n","\n","        eps = privacy_engine.get_epsilon(DELTA)  if use_dp else None\n","\n","        print(f\"[{'DP-SGD' if use_dp else 'Standard SGD'}] Epoch {epoch}: \"\n","            + f\"train_loss={train_loss:.4f}, \"\n","            + f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}%\"\n","            + f\", ε={eps:.4f}\" if use_dp else \"\")\n","\n","        if pruning_type == \"LTH\" and epoch == 1:\n","            rewind_state = copy.deepcopy(model.state_dict())\n","            print(\"Saved early-rewind weights for LTH\")\n","\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), best_model_path)\n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= PATIENCE:\n","            print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {PATIENCE} epochs).\")\n","            break\n","\n","        if pruning_type == \"LTH\" and epoch != 1 and epoch in prune_epochs:\n","          lth_step += 1\n","          remaining_k = (1 - final_sparsity) ** (lth_step / len(prune_epochs))\n","          target_sparsity = 1 - remaining_k\n","          print(f\"Pruning {target_sparsity*100:.2f}% at epoch {epoch}\")\n","          model, new_mask = weight_pruning(model, amount=target_sparsity, return_mask=True)\n","          global_mask = new_mask\n","\n","          rewound = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in rewound:\n","                  rewound[name] = rewound[name] * mask   # apply lottery ticket mask\n","\n","          model.load_state_dict(rewound)\n","          epochs_no_improve = 0\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","\n","    if pruning_type == \"POST\":\n","      prune_start_time = time.time()\n","      model, _ = weight_pruning(model, final_sparsity)\n","      final_sparsity = calculate_sparsity(model)\n","\n","      for ft_epoch in range(1, PRUNE_EPOCHS + 1):\n","            train_loss = train_one_epoch(model, train_loader_dp, optimizer)\n","            val_loss, val_acc = evaluate(model, val_loader)\n","            eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","\n","            print(f\"[Fine Tuning Epoch {ft_epoch}] val_acc={val_acc:.4f}%\"\n","                  + (f\", ε={eps:.4f}\" if use_dp else \"\"))\n","            if val_acc > best_val_acc:\n","                best_val_acc = val_acc\n","                torch.save(model.state_dict(), best_model_path)\n","\n","      prune_end_time = time.time()\n","      prune_time = prune_end_time - prune_start_time\n","      end_time = time.time()\n","      total_time = end_time - start_time\n","\n","    # test on best model\n","    if pruning_type == \"LTH\":\n","      # reconstruct final winning ticket\n","      if global_mask is None:\n","          ticket_state = copy.deepcopy(rewind_state)\n","      else:\n","          ticket_state = copy.deepcopy(rewind_state)\n","          for name, mask in global_mask.items():\n","              if name in ticket_state:\n","                  ticket_state[name] = ticket_state[name] * mask\n","      model.load_state_dict(ticket_state)\n","    elif pruning_type == \"POST\":\n","      # keep already pruned & fine-tuned model\n","      pass\n","    else:\n","      model.load_state_dict(torch.load(best_model_path))\n","    test_loss, test_acc = evaluate(model, test_loader)\n","    final_eps = privacy_engine.get_epsilon(DELTA) if use_dp else None\n","    final_sparsity = calculate_sparsity(model)\n","\n","    print(f\"\\n=== Results for {'DP-SGD' if use_dp else 'Standard-SGD'} with {pruning_type if pruning_type else 'No'} Pruning ===\")\n","    print(f\"Test Accuracy: {test_acc:.2f}%\")\n","    print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n","    if use_dp:\n","        print(f\"Final ε = {final_eps:.3f}\")\n","    print(f\"Train Time:     {total_time:.2f} sec\")\n","    if pruning_type:\n","        print(f\"Sparsity:       {final_sparsity:.2f}%\")\n","\n","    return {\n","        \"val_acc\": best_val_acc,\n","        \"test_acc\": test_acc,\n","        \"epsilon\": final_eps,\n","        \"train_time\": total_time,\n","        \"sparsity\": final_sparsity\n","    }"]},{"cell_type":"markdown","metadata":{"id":"H7wfuU3iJ7M9"},"source":["# Baseline: No Differential Privacy"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":743807,"status":"ok","timestamp":1765046673636,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"LT9id_MwJxpC","outputId":"76355ec7-3b25-449f-f0ac-97b69c56f701"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline for fixed (8, 1e-05)-DP\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=2.1974, val_loss=2.0822, val_acc=25.8300%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=2.0328, val_loss=2.0046, val_acc=29.6300%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9762, val_loss=1.9634, val_acc=31.5100%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9503, val_loss=1.9499, val_acc=32.1900%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.9309, val_loss=1.9508, val_acc=32.5500%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.9272, val_loss=1.9219, val_acc=33.8000%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.8984, val_loss=1.9013, val_acc=34.7900%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8821, val_loss=1.8758, val_acc=35.1200%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.8556, val_loss=1.8659, val_acc=36.5200%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.8482, val_loss=1.8491, val_acc=37.3800%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.8079, val_loss=1.8384, val_acc=37.4600%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.8191, val_loss=1.8037, val_acc=38.4900%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.8024, val_loss=1.8075, val_acc=38.5900%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7901, val_loss=1.8226, val_acc=38.7900%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7898, val_loss=1.7858, val_acc=40.1200%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7757, val_loss=1.8069, val_acc=39.8300%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7916, val_loss=1.8037, val_acc=40.3100%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7835, val_loss=1.8247, val_acc=41.1400%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.7938, val_loss=1.8022, val_acc=41.4600%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.7804, val_loss=1.8390, val_acc=41.5900%, ε=7.9939\n","\n","=== Results for DP-SGD with No Pruning ===\n","Test Accuracy: 41.88%\n","Best Val Acc: 41.59%\n","Final ε = 7.994\n","Train Time:     721.79 sec\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 41.59,\n"," 'test_acc': 41.88,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 721.7920761108398,\n"," 'sparsity': np.float64(0.0)}"]},"metadata":{},"execution_count":23}],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":741827,"status":"ok","timestamp":1765042549935,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"pDIkJaqVQZc8","outputId":"80cb03c6-3cee-484e-9d6b-b0769d442d73"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline with pre weight pruning\n","Pruned model sparsity = 29.93%\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=2.1971, val_loss=2.0639, val_acc=26.3100%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=2.0120, val_loss=1.9694, val_acc=30.8800%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9464, val_loss=1.9367, val_acc=31.9000%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9171, val_loss=1.9040, val_acc=33.4000%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8927, val_loss=1.8855, val_acc=34.3400%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.8739, val_loss=1.8638, val_acc=35.8700%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.8476, val_loss=1.8531, val_acc=36.5300%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8313, val_loss=1.8257, val_acc=37.2000%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.8217, val_loss=1.8074, val_acc=38.3000%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.7982, val_loss=1.8088, val_acc=38.8900%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.8019, val_loss=1.8032, val_acc=39.5200%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.7875, val_loss=1.7836, val_acc=40.4200%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.7845, val_loss=1.7929, val_acc=40.8700%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7658, val_loss=1.7768, val_acc=41.9400%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7640, val_loss=1.8021, val_acc=41.8100%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7643, val_loss=1.7623, val_acc=42.3800%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7383, val_loss=1.7813, val_acc=42.6400%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7418, val_loss=1.7677, val_acc=43.3100%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.7516, val_loss=1.7709, val_acc=43.6600%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.7482, val_loss=1.7637, val_acc=44.2500%, ε=7.9939\n","\n","=== Results for DP-SGD with PRE Pruning ===\n","Test Accuracy: 44.84%\n","Best Val Acc: 44.25%\n","Final ε = 7.994\n","Train Time:     719.80 sec\n","Sparsity:       0.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 44.25,\n"," 'test_acc': 44.84,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 719.7968690395355,\n"," 'sparsity': np.float64(0.0)}"]},"metadata":{},"execution_count":20}],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WutQvKhLs6Cc","executionInfo":{"status":"ok","timestamp":1765043830763,"user_tz":300,"elapsed":746152,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}},"outputId":"3e3202bf-a144-4e8c-c87f-3b769af5325d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline with post weight pruning\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=2.1828, val_loss=2.0609, val_acc=25.6600%, ε=3.5278\n","[DP-SGD] Epoch 2: train_loss=2.0294, val_loss=2.0015, val_acc=27.7300%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9730, val_loss=1.9422, val_acc=31.0200%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.9227, val_loss=1.8925, val_acc=33.4400%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8817, val_loss=1.8511, val_acc=34.9700%, ε=5.0010\n","[DP-SGD] Epoch 6: train_loss=1.8444, val_loss=1.8582, val_acc=35.6000%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.8478, val_loss=1.8315, val_acc=37.0000%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8298, val_loss=1.8111, val_acc=38.1500%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.8142, val_loss=1.8281, val_acc=38.6500%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.8163, val_loss=1.8037, val_acc=39.4000%, ε=6.1795\n","[DP-SGD] Epoch 11: train_loss=1.8069, val_loss=1.8111, val_acc=40.1000%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.7801, val_loss=1.8086, val_acc=40.8400%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.7824, val_loss=1.7857, val_acc=41.4700%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.7746, val_loss=1.7722, val_acc=42.2600%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.7590, val_loss=1.7795, val_acc=42.4100%, ε=7.1431\n","[DP-SGD] Epoch 16: train_loss=1.7695, val_loss=1.7836, val_acc=42.1900%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.7605, val_loss=1.7984, val_acc=42.3400%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.7578, val_loss=1.7956, val_acc=42.9800%, ε=7.6640\n","Pruned model sparsity = 29.93%\n","[Fine Tuning Epoch 1] val_acc=42.9800%, ε=7.8305\n","[Fine Tuning Epoch 2] val_acc=43.4300%, ε=7.9939\n","\n","=== Results for DP-SGD with POST Pruning ===\n","Test Accuracy: 43.96%\n","Best Val Acc: 43.43%\n","Final ε = 7.994\n","Train Time:     724.13 sec\n","Sparsity:       0.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 43.43,\n"," 'test_acc': 43.96,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 724.1310150623322,\n"," 'sparsity': np.float64(0.0)}"]},"metadata":{},"execution_count":21}],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Und-QJTDeVB","executionInfo":{"status":"ok","timestamp":1765044567244,"user_tz":300,"elapsed":736475,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"}},"outputId":"21154961-e6a2-4dba-c432-2fb1194b998d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline with iterative pruning\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=2.1913, val_loss=2.0354, val_acc=28.3600%, ε=3.5278\n","Saved early-rewind weights for LTH\n","[DP-SGD] Epoch 2: train_loss=1.9857, val_loss=1.9489, val_acc=30.7700%, ε=4.0227\n","[DP-SGD] Epoch 3: train_loss=1.9226, val_loss=1.9228, val_acc=32.6400%, ε=4.3957\n","[DP-SGD] Epoch 4: train_loss=1.8925, val_loss=1.8967, val_acc=34.3600%, ε=4.7147\n","[DP-SGD] Epoch 5: train_loss=1.8764, val_loss=1.8505, val_acc=35.7200%, ε=5.0010\n","Pruning 11.21% at epoch 5\n","Pruned model sparsity = 11.18%\n","[DP-SGD] Epoch 6: train_loss=1.9734, val_loss=1.9432, val_acc=31.4000%, ε=5.2647\n","[DP-SGD] Epoch 7: train_loss=1.9163, val_loss=1.9130, val_acc=33.3200%, ε=5.5113\n","[DP-SGD] Epoch 8: train_loss=1.8894, val_loss=1.8932, val_acc=34.5900%, ε=5.7445\n","[DP-SGD] Epoch 9: train_loss=1.8712, val_loss=1.8602, val_acc=35.6000%, ε=5.9666\n","[DP-SGD] Epoch 10: train_loss=1.8504, val_loss=1.8455, val_acc=36.5600%, ε=6.1795\n","Pruning 21.16% at epoch 10\n","Pruned model sparsity = 21.11%\n","[DP-SGD] Epoch 11: train_loss=1.9647, val_loss=1.9446, val_acc=31.8200%, ε=6.3845\n","[DP-SGD] Epoch 12: train_loss=1.9089, val_loss=1.9038, val_acc=32.9800%, ε=6.5826\n","[DP-SGD] Epoch 13: train_loss=1.8857, val_loss=1.8633, val_acc=34.8900%, ε=6.7746\n","[DP-SGD] Epoch 14: train_loss=1.8455, val_loss=1.8409, val_acc=36.0700%, ε=6.9613\n","[DP-SGD] Epoch 15: train_loss=1.8218, val_loss=1.8291, val_acc=36.8100%, ε=7.1431\n","Pruning 30.00% at epoch 15\n","Pruned model sparsity = 29.93%\n","[DP-SGD] Epoch 16: train_loss=1.9527, val_loss=1.9213, val_acc=32.4200%, ε=7.3206\n","[DP-SGD] Epoch 17: train_loss=1.9054, val_loss=1.8799, val_acc=33.9500%, ε=7.4941\n","[DP-SGD] Epoch 18: train_loss=1.8577, val_loss=1.8580, val_acc=35.2500%, ε=7.6640\n","[DP-SGD] Epoch 19: train_loss=1.8539, val_loss=1.8515, val_acc=35.7900%, ε=7.8305\n","[DP-SGD] Epoch 20: train_loss=1.8203, val_loss=1.8272, val_acc=37.2500%, ε=7.9939\n","\n","=== Results for DP-SGD with LTH Pruning ===\n","Test Accuracy: 29.47%\n","Best Val Acc: 37.25%\n","Final ε = 7.994\n","Train Time:     714.26 sec\n","Sparsity:       30.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 37.25,\n"," 'test_acc': 29.47,\n"," 'epsilon': np.float64(7.993863084259577),\n"," 'train_time': 714.2626428604126,\n"," 'sparsity': np.float64(30.001029018316526)}"]},"metadata":{},"execution_count":22}],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"markdown","metadata":{"id":"8F8KH8ZWH9ZB"},"source":["MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3338215,"status":"ok","timestamp":1764025108823,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":480},"id":"c05kbWWJOE3U","outputId":"860c1dc1-c2b2-4235-e2bb-f02c07f39f22"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline for fixed (8, 1e-05)-DP\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=0.9209, val_loss=0.5501, val_acc=86.9200%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5346, val_loss=0.5889, val_acc=88.6300%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5745, val_loss=0.6062, val_acc=89.2900%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5750, val_loss=0.6006, val_acc=89.9100%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5598, val_loss=0.5834, val_acc=90.3900%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5558, val_loss=0.5712, val_acc=90.9200%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5358, val_loss=0.5597, val_acc=91.3200%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5151, val_loss=0.5546, val_acc=91.4100%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.4976, val_loss=0.5380, val_acc=91.7400%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.4853, val_loss=0.5150, val_acc=92.0300%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.4758, val_loss=0.5104, val_acc=92.2300%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.4767, val_loss=0.5070, val_acc=92.2700%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.4495, val_loss=0.5010, val_acc=92.4000%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.4420, val_loss=0.5061, val_acc=92.5700%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.4555, val_loss=0.5006, val_acc=92.8700%, ε=7.1710\n","[DP-SGD] Epoch 16: train_loss=0.4413, val_loss=0.4885, val_acc=92.9300%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.4257, val_loss=0.4859, val_acc=92.8600%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.4321, val_loss=0.4877, val_acc=93.2000%, ε=7.6817\n","[DP-SGD] Epoch 19: train_loss=0.4293, val_loss=0.4939, val_acc=93.0700%, ε=7.8449\n","[DP-SGD] Epoch 20: train_loss=0.4401, val_loss=0.4769, val_acc=93.1200%, ε=8.0050\n","\n","=== Results for DP-SGD with No Pruning ===\n","Test Accuracy: 93.93%\n","Best Val Acc: 93.20%\n","Final ε = 8.005\n","Train Time:     3316.64 sec\n"]},{"data":{"text/plain":["{'val_acc': 93.2,\n"," 'test_acc': 93.93,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3316.64049744606,\n"," 'sparsity': np.float64(0.0)}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["print(f\"\\nRunning DP-SGD baseline for fixed ({TARGET_EPSILON}, {TARGET_DELTA})-DP\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3459770,"status":"ok","timestamp":1765050704024,"user":{"displayName":"MEGHA MARAN","userId":"04090563790326142219"},"user_tz":300},"id":"-xsO3AzzH_QI","outputId":"b89d329e-78a0-4b8b-bd83-44882aefad6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running DP-SGD baseline with pre weight pruning\n","Pruned model sparsity = 29.99%\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"output_type":"stream","name":"stdout","text":["[DP-SGD] Epoch 1: train_loss=0.9343, val_loss=0.5505, val_acc=86.1700%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5493, val_loss=0.5734, val_acc=88.3600%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5771, val_loss=0.5851, val_acc=89.2700%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5542, val_loss=0.5802, val_acc=89.8700%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5661, val_loss=0.5744, val_acc=90.2500%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5670, val_loss=0.5486, val_acc=90.6300%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5417, val_loss=0.5444, val_acc=91.0600%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5107, val_loss=0.5313, val_acc=91.1100%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.4979, val_loss=0.5152, val_acc=91.5700%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.4934, val_loss=0.4914, val_acc=92.0700%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.4781, val_loss=0.4917, val_acc=92.0500%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.4612, val_loss=0.4848, val_acc=92.2900%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.4463, val_loss=0.4756, val_acc=92.5300%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.4446, val_loss=0.4815, val_acc=92.6700%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.4457, val_loss=0.4742, val_acc=92.7500%, ε=7.1710\n","[DP-SGD] Epoch 16: train_loss=0.4328, val_loss=0.4667, val_acc=93.0600%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.4343, val_loss=0.4668, val_acc=92.7300%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.4336, val_loss=0.4649, val_acc=93.0200%, ε=7.6817\n","[DP-SGD] Epoch 19: train_loss=0.4073, val_loss=0.4728, val_acc=93.0800%, ε=7.8449\n","[DP-SGD] Epoch 20: train_loss=0.4168, val_loss=0.4519, val_acc=93.1100%, ε=8.0050\n","\n","=== Results for DP-SGD with PRE Pruning ===\n","Test Accuracy: 94.22%\n","Best Val Acc: 93.11%\n","Final ε = 8.005\n","Train Time:     3439.19 sec\n","Sparsity:       0.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'val_acc': 93.11,\n"," 'test_acc': 94.22,\n"," 'epsilon': np.float64(8.005044757651065),\n"," 'train_time': 3439.1912891864777,\n"," 'sparsity': np.float64(0.0)}"]},"metadata":{},"execution_count":27}],"source":["print(\"\\nRunning DP-SGD baseline with pre weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"PRE\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGXspQ4eICC4","outputId":"625148aa-f891-41bd-c454-42b236522500"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with post weight pruning\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=1.0450, val_loss=0.5471, val_acc=85.5200%, ε=3.6072\n","[DP-SGD] Epoch 2: train_loss=0.5385, val_loss=0.5670, val_acc=88.3700%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5504, val_loss=0.5713, val_acc=89.1700%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5532, val_loss=0.5710, val_acc=89.5900%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5531, val_loss=0.5660, val_acc=90.2400%, ε=5.0671\n","[DP-SGD] Epoch 6: train_loss=0.5318, val_loss=0.5489, val_acc=90.6900%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5339, val_loss=0.5466, val_acc=90.9900%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5150, val_loss=0.5530, val_acc=91.2100%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.5218, val_loss=0.5377, val_acc=91.4900%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.5046, val_loss=0.5451, val_acc=91.5800%, ε=6.2255\n","[DP-SGD] Epoch 11: train_loss=0.5021, val_loss=0.5327, val_acc=91.8500%, ε=6.4267\n"]}],"source":["print(\"\\nRunning DP-SGD baseline with post weight pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"POST\", final_sparsity=0.3, fixed_privacy_budget=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrcaGz2aIEaq","outputId":"60b0902f-d4b5-4889-9e62-38bab78585db"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Running DP-SGD baseline with iterative pruning\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-1715503071.py:10: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n","  loss.backward()\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[DP-SGD] Epoch 1: train_loss=0.9298, val_loss=0.5437, val_acc=86.6500%, ε=3.6072\n","Saved early-rewind weights for LTH\n","[DP-SGD] Epoch 2: train_loss=0.5482, val_loss=0.5643, val_acc=88.6300%, ε=4.1009\n","[DP-SGD] Epoch 3: train_loss=0.5456, val_loss=0.5878, val_acc=89.3700%, ε=4.4702\n","[DP-SGD] Epoch 4: train_loss=0.5507, val_loss=0.5872, val_acc=89.8200%, ε=4.7850\n","[DP-SGD] Epoch 5: train_loss=0.5784, val_loss=0.5845, val_acc=90.1800%, ε=5.0671\n","Pruning 11.21% at epoch 5\n","Pruned model sparsity = 11.21%\n","[DP-SGD] Epoch 6: train_loss=0.5135, val_loss=0.5455, val_acc=88.7600%, ε=5.3266\n","[DP-SGD] Epoch 7: train_loss=0.5666, val_loss=0.5855, val_acc=89.0500%, ε=5.5691\n","[DP-SGD] Epoch 8: train_loss=0.5739, val_loss=0.5678, val_acc=89.8900%, ε=5.7982\n","[DP-SGD] Epoch 9: train_loss=0.5358, val_loss=0.5614, val_acc=90.3400%, ε=6.0164\n","[DP-SGD] Epoch 10: train_loss=0.5397, val_loss=0.5660, val_acc=90.4400%, ε=6.2255\n","Pruning 21.16% at epoch 10\n","Pruned model sparsity = 21.15%\n","[DP-SGD] Epoch 11: train_loss=0.5100, val_loss=0.5523, val_acc=88.7700%, ε=6.4267\n","[DP-SGD] Epoch 12: train_loss=0.5480, val_loss=0.5651, val_acc=89.5000%, ε=6.6211\n","[DP-SGD] Epoch 13: train_loss=0.5582, val_loss=0.5636, val_acc=90.0000%, ε=6.8096\n","[DP-SGD] Epoch 14: train_loss=0.5460, val_loss=0.5734, val_acc=90.3500%, ε=6.9927\n","[DP-SGD] Epoch 15: train_loss=0.5409, val_loss=0.5604, val_acc=90.4700%, ε=7.1710\n","Pruning 30.00% at epoch 15\n","Pruned model sparsity = 29.99%\n","[DP-SGD] Epoch 16: train_loss=0.5020, val_loss=0.5484, val_acc=88.7600%, ε=7.3450\n","[DP-SGD] Epoch 17: train_loss=0.5277, val_loss=0.5678, val_acc=89.7600%, ε=7.5151\n","[DP-SGD] Epoch 18: train_loss=0.5577, val_loss=0.5777, val_acc=90.0400%, ε=7.6817\n"]}],"source":["print(\"\\nRunning DP-SGD baseline with iterative pruning\")\n","run_experiment(dataset=DATASET_NAME, use_dp=True, pruning_type=\"LTH\", final_sparsity=0.3, fixed_privacy_budget=True, prune_epochs=[5, 10, 15])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWTtNpkFIHQj"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}